name: linux-binaries-test

on:
  pull_request:
  push:
    branches:
      - master
      - dev
    tags:
      - v*

defaults:
  run:
    shell: bash

jobs:
  #
  # Produce a "full" source-archive, that is, including source from submodules
  #
  # This is done to provide the source-archive for users in environments without
  # submodule access and for the containers in the workflow which does not have
  # a recent enough version of git do pull down the modules
  #
  source-archive-gen:
    runs-on: ubuntu-latest

    steps:
    - name: Grab source
      uses: actions/checkout@v2

    - name: Prepare Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.x'

    - name: Generate Full Source Archive
      run: |
        pip install git-archive-all
        make gen-src-archive

    - name: Upload source archive
      uses: actions/upload-artifact@v2
      with:
        name: archive-src
        path: build/*.src.tar.gz

  # Grab the source and build on self-hosted, matching the CPU on which it will
  # be tested. This is done, since SPDK/DPDK is build with "-march=native", and
  # thus needs to run on a CPU with the same ISA
  linux-binaries:
    runs-on: self-hosted
    needs: source-archive-gen

    container: debian:bullseye

    steps:
    - name: Self-hosted, prep
      run: |
        rm -rf *
        ls

    - name: Container-prep, get the full-source-archive
      uses: actions/download-artifact@v2
      with:
        name: archive-src

    - name: Unpack the full-source-archive
      run: |
        ls
        tar xzf *.src.tar.gz
        rm *.src.tar.gz
        mv xnvme-* xnvme

    - name: Install build-requirements
      run: |
        cd xnvme
        source scripts/pkgs/debian-bullseye.sh
        [[ ! -f "/usr/bin/python" ]] && ln -s /usr/bin/python3.8 /usr/bin/python || true

    - name: Configure, the build
      run: |
        cd xnvme
        make config

    - name: Dump, the compile-commands and machine
      run: |
        cat /proc/cpuinfo
        cat xnvme/build/compile_commands.json

    - name: Build!
      run: |
        cd xnvme
        make

    - name: Install
      run: |
        cd xnvme
        make install

    - name: Execute 'xnvme enum'
      run: xnvme enum

    - name: Execute 'xnvme library-info'
      run: xnvme library-info

    # The is intended for testing and for quick-preview for those that do not
    # want to build from source. It will later be used for installation inside a
    # docker-container, as well as inside of a qemu-guest
    - name: Upload Archive
      uses: actions/upload-artifact@v2
      with:
        name: archive-bin
        path: xnvme/build/*.bin.tar.gz

    - name: Upload Debian Packages
      uses: actions/upload-artifact@v2
      with:
        name: pkg-deb
        path: xnvme/build/*.deb

    - name: Upload fio binary
      uses: actions/upload-artifact@v2
      with:
        name: fio-bin
        path: xnvme/third-party/fio/repos/fio

    - name: Upload the SPDK fio io-engines
      uses: actions/upload-artifact@v2
      with:
        name: fio-spdk-ioengines
        path: xnvme/third-party/spdk/repos/build/fio/*

    # The git-hub-actions-runner does not cleanup after itself
    - name: Self-hosted, cleanup
      if: always()
      run: rm -rf *

  # Test the pkg-deb built on Debian Bullseye / 11 using CIJOE
  linux-testing:
    needs: linux-binaries

    runs-on: self-hosted
    container:
      image: refenv/qemu-nvme:latest
      options: --privileged

    steps:
    - name: Self-hosted, prep
      run: rm -rf *

    - name: Container-prep, define env.
      run: |
        source /opt/scripts/suitup.sh

        echo "RESULTS=/tmp/results" >> $GITHUB_ENV
        echo "TARGET_ENV=${CIJ_ENVS}/refenv-xnvme-qemu.sh" >> $GITHUB_ENV
        echo "CLOUD_IMG_URL=https://cloud.debian.org/images/cloud/bullseye/daily/20210425-618/debian-11-generic-amd64-daily-20210425-618.qcow2" >> $GITHUB_ENV

    - name: Container-prep, download Debian packages
      uses: actions/download-artifact@v2
      with:
        name: pkg-deb

    - name: Container-prep, download fio binary
      uses: actions/download-artifact@v2
      with:
        name: fio-bin

    - name: Container-prep, download SPDK fio io-engines
      uses: actions/download-artifact@v2
      with:
        name: fio-spdk-ioengines

    - name: Container-prep, start the SSH server
      run: service ssh restart

    - name: CIJOE, re-install as pre-release and install the xNVMe package
      run: |
        pip3 uninstall -y cijoe
        pip3 install --pre cijoe
        pip3 install --pre cijoe-pkg-xnvme

    - name: CIJOE, define and create result folder
      run: |
        mkdir -p ${RESULTS}/

    - name: CIJOE/QEMU, provision guest using Debian cloud image
      run: |
        source /opt/scripts/suitup.sh
        qemu::img_from_url "${CLOUD_IMG_URL}"

    - name: CIJOE/QEMU, start the guest
      run: |
        source /opt/scripts/suitup.sh
        source "${CIJ_TESTFILES}/qemu6_pcie_nvme_1c2ns_nvm_zns.sh"
        qemu_setup_pcie
        QEMU_ARGS_EXTRA="$QEMU_SETUP_PCIE"
        qemu::run

    - name: CIJOE/QEMU, install Debian packages in guest
      run: |
        source /opt/scripts/suitup.sh

        for deb in *.deb; do
          ssh::push "$deb" "/tmp/"
        done

        ssh::cmd "dpkg -i /tmp/*.deb"

    - name: CIJOE/QEMU, dump fio binary and SPDK io-engines in guest
      run: |
        source /opt/scripts/suitup.sh
        ssh::cmd "mkdir /opt/aux"
        ssh::push "fio" "/opt/aux/"
        ssh::push "spdk_nvme" "/opt/aux/"
        ssh::push "spdk_bdev" "/opt/aux/"
        ssh::cmd "find /opt/aux"
        ssh::cmd "chmod +x /opt/aux/fio"

    - name: CIJOE/QEMU, check binaries are available
      if: always()
      run: |
        source /opt/scripts/suitup.sh
        ssh::cmd "hostname || true"
        ssh::cmd "which xnvme || true"
        ssh::cmd "whereis which zoned || true"
        ssh::cmd "xnvme library-info || true"
        ssh::cmd "xnvme enum || true"

    - name: CIJOE/QEMU, run testplans
      if: always()
      run: |
        source /opt/scripts/suitup.sh
        cij_runner \
          --testplan \
          $CIJ_TESTPLANS/xnvme-linux-bd-ncs.plan \
          $CIJ_TESTPLANS/xnvme-linux-bd-zcs.plan \
          $CIJ_TESTPLANS/xnvme-linux-nvme-base.plan \
          $CIJ_TESTPLANS/xnvme-linux-nvme-ncs.plan \
          $CIJ_TESTPLANS/xnvme-linux-nvme-zcs.plan \
          --env ${TARGET_ENV} \
          --output ${RESULTS}

    - name: CIJOE/QEMU, kill the guest
      if: always()
      run: |
        source /opt/scripts/suitup.sh
        qemu::kill

    - name: CIJOE, result-log-dump on error
      if: failure()
      run: find ${RESULTS} -name "*.log" | xargs cat

    - name: CIJOE, generate report from results
      if: always()
      run: |
        source /opt/scripts/suitup.sh
        cij_reporter --output "${RESULTS}"

    - name: CIJOE, upload test results and report
      uses: actions/upload-artifact@v2
      if: always()
      with:
        name: test-results
        path: ${{ env.RESULTS }}/*

    # The git-hub-actions-runner does not cleanup after itself
    - name: Self-hosted, cleanup
      if: always()
      run: rm -rf *
