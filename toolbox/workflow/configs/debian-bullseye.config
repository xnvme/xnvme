---
transport:
  ssh:  # The SSH options are passed verbatim to paramiko; see https://www.paramiko.org/
    hostname: localhost
    port: 4200
    username: root
    password: root

os:
  name: 'debian'
  version: 'bullseye'

# cloudinit:
# These are used by joe.qemu.wrapper.Guest().cloudinit() and the worklet "qemu.guest_provision" to
# "provision" a guest with the given OS. That is, boot it up, configure the OS, then shut it down
# ready for use.
# The 'joe.qemu.auxilary' files provide initialization-files (user-data and meta-data) and a
# "trick" to inject a public-key into the guest.
cloudinit:
  bullseye:
    url: "https://cloud.debian.org/images/cloud/bullseye/daily/latest/debian-11-generic-amd64-daily.qcow2"
    img: "{{ local.env.HOME}}/images/cloudinit/debian-11-generic-amd64-daily.qcow2"
    meta: "{{ resources.auxilary['qemu.cloudinit-debian-bullseye-meta'] }}"
    user: "{{ resources.auxilary['qemu.cloudinit-debian-bullseye-user'] }}"
#    pubkey: "keys/guest_key.pub"

  freebsd:
    url: "https://refenv.fra1.digitaloceanspaces.com/freebsd13-ufs-ksrc.qcow2"
    img: "{{ local.env.HOME}}/images/cloudinit/freebsd13-ufs-ksrc.qcow2"
    meta: "{{ resources.auxilary['qemu.cloudinit-freebsd-13-meta'] }}"
    user: "{{ resources.auxilary['qemu.cloudinit-freebsd-13-user'] }}"
#    pubkey: "keys/guest_key.pub"

# boot_images:
# qemu images, could be cloudinit images which have been processed through initialization process
boot_images:
  bullseye:
    url: "https://refenv.fra1.digitaloceanspaces.com/boot_images/debian-bullseye-amd64.qcow2"
    img: "{{ local.env.HOME}}/images/boot_images/debian-bullseye-amd64.qcow2"

  freebsd:
    url: "https://refenv.fra1.digitaloceanspaces.com/boot_images/freebsd-13.1-ksrc-amd64.qcow2"
    img: "{{ local.env.HOME}}/images/boot_images/freebsd-13.1-ksrc-amd64.qcow2"

# qemu:
qemu:
  repository:
    upstream: "https://github.com/qemu/qemu.git"
    path: "{{ local.env.HOME }}/git/qemu"
    tag: "v7.1.0"

  build:
    prefix: "{{ local.env.HOME }}/opt/qemu"

#  system_bin: "{{ local.env.HOME }}/opt/qemu/bin/qemu-system-x86_64"
  system_bin: "/opt/qemu/bin/qemu-system-x86_64"
  img_bin: "qemu-img"

  guests:
    bullseye:
      path: "{{ local.env.HOME }}/guests/bullseye-amd64"

      boot_img: "bullseye"
      cloudinit: "bullseye"

      # Plain qemu-system arguments (-cpu, -machine, -smp, etc), the
      # sub-keys are e.g. "-machine type=..."
      system_args:
        machine:
          type: "q35,kernel_irqchip=split,accel=kvm"
        cpu: "host"
        smp: 4
        m: "6G"
        device: "intel-iommu,pt=on,intremap=on"

      # These are 'fancy' arguments, with special handling in the joe.core.qemu.wrapper.Guest()
      fancy:
        # host_share: enables the the guest to mount a directory from the host by running:
        # "mount -t 9p -o trans=virtio hostshare foo -oversion=9p2000.L"
        #host_share: "{{ local.env.HOME }}/git"

        # tcp_forward: enables the host access to the 'guest' port via the 'host' port. Useful for
        # doing things like SSH-ing into the guest
        tcp_forward:
          host: 4200
          guest: 22

      # This string is appended to the end of the qemu-system command-line, a wildcard for whatever
      # you need. You can also consider writing a worklet to serve your needs. See the
      # "qemu.guest_start" and "qemu.guest_start_nvme" worklets for reference.
      extra_args: ""

devices:
- uri: "/dev/nvme0n1"
  nsid: 1
  labels: ["dev", "bdev", "nvm", "scc"]
  driver_attachment: "kernel"
  spdk_conf:
- uri: "/dev/ng0n1"
  nsid: 1
  labels: ["dev", "cdev", "nvm", "scc"]
  driver_attachment: "kernel"
  spdk_conf:
- uri: "0000:03:00.0"
  nsid: 1
  labels: ["dev", "pcie", "nvm", "scc"]
  driver_attachment: "userspace"
  spdk_conf:
#- uri: "127.0.0.1:4420"
#  nsid: 1
#  labels: ["dev", "fabrics", "nvm"]
#  spdk_conf: ~

- uri: "/dev/nvme0n2"
  nsid: 2
  labels: ["dev", "bdev", "zns", "zrwa"]
  driver_attachment: "kernel"
  spdk_conf:
- uri: "/dev/ng0n2"
  nsid: 2
  labels: ["dev", "cdev", "zns", "zrwa"]
  driver_attachment: "kernel"
  spdk_conf:
- uri: "0000:03:00.0"
  nsid: 2
  labels: ["dev", "pcie", "zns", "zrwa"]
  driver_attachment: "userspace"
  spdk_conf:
#- uri: "127.0.0.1:4420"
#  nsid: 2
#  labels: ["dev", "fabrics", "zns"]
#  spdk_conf: ~

- uri: "/tmp/xnvme-testfile.bin"
  nsid: 1
  labels: ["file"]
  driver_attachment: "kernel"
  spdk_conf:

xnvme:
  repository:
    upstream: "https://github.com/OpenMPDK/xNVMe.git"
    path: "/root/git/xnvme"

  source:
    path: "/tmp/xnvme_source"

  build:
    type: "debug"

# Declaration of where fio is located on the test-target and which IO-engines it has available
fio:
  repository:
    upstream: "https://github.com/axboe/fio.git"
    path: "/root/git/fio"
    tag: "fio-3.31"

  build:
    prefix: "/opt/fio"

  #bin: "/opt/fio/bin/fio"
  bin: "/opt/fio_custom/fio"

  engines:
    libaio:
      type: builtin
    io_uring:
      type: builtin
    io_uring_cmd:
      type: builtin

    xnvme:
      path: /usr/local/lib/x86_64-linux-gnu/libxnvme-fio-engine.so
      type: external_dynamic
    spdk_nvme:
      path: /opt/aux/spdk_nvme
      type: external_preload
    spdk_bdev:
      path: /opt/aux/spdk_bdev
      type: external_preload

linux:
  repository:
    remote: "https://github.com/linux/linux.git"
    path: "{{ local.env.HOME }}/git/linux"
    tag: "v5.19"
